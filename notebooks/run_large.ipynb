{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 32762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 26 18:06:53 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   48C    P2    44W / 200W |    598MiB /  8116MiB |     11%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0       973      G   /usr/lib/xorg/Xorg                           238MiB |\n",
      "|    0      2124      G   compiz                                       136MiB |\n",
      "|    0     17854      G   ...-token=7552DA9E629E8F607A76033482FFE4CE    43MiB |\n",
      "|    0     29904      C   /usr/bin/python                              167MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python shalowunet.py --mode export     --checkpoint output/shallowunet/1 --crop_size 512 --output_dir output/shallowunet/1/frozen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "checkpoint = 'output/shallowunet/1'\n",
    "frozen_dir = checkpoint+'/frozen'\n",
    "os.system('rm -r {}'.format(frozen_dir))\n",
    "cmd = 'python shalowunet.py --mode export \\\n",
    "    --checkpoint {} --crop_size 512 --output_dir {}'.format(checkpoint, frozen_dir)\n",
    "print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import math\n",
    "\n",
    "\n",
    "def get_tensor_by_name(name):\n",
    "    name_on_device = '{}:0'.format(name)\n",
    "    return tf.get_default_graph().get_tensor_by_name(name_on_device)\n",
    "\n",
    "def load_image(path, verbal=False):\n",
    "    print('---------------------------\\nprocess:', path)\n",
    "    name = path.split('/')[-1].split('.')[0]\n",
    "    image = cv2.imread(path)\n",
    "    p = 286/256\n",
    "    image = cv2.resize(image, (0,0), fx=p*0.3, fy=p*0.3)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def write(path, image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return cv2.imwrite(path, image)\n",
    "print('Finish')\n",
    "def get_name(path):\n",
    "    name, _ = os.path.splitext(os.path.basename(path))\n",
    "    return name   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(image, output_image, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    inp = image\n",
    "    out1 = output_image[:,:,0]\n",
    "    out2 = output_image[:,:,-1]\n",
    "    #cv2.imwrite(os.path.join(save_dir, 'input.png'), inp)\n",
    "    write(os.path.join(save_dir, 'input.png'), inp)\n",
    "    cv2.imwrite(os.path.join(save_dir, 'output1.png'), 255-out1)\n",
    "    cv2.imwrite(os.path.join(save_dir, 'output2.png'), 255-out2)\n",
    "    print('Output: ', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(sess, feed_image, batch_size=8):\n",
    "    batch_input = sess.run(batch_input_tensor, {inputs:feed_image})\n",
    "    rv = []\n",
    "    \n",
    "    for i in range(0, len(batch_input), batch_size):\n",
    "        print('\\r {:0.2f} %'.format(i/len(batch_input)), end='')\n",
    "        rv.append(sess.run(batch_output_tensor, {batch_input_placeholder: batch_input[i:i+batch_size]}))\n",
    "    output_feed = np.concatenate(rv, axis=0)\n",
    "    return sess.run(outputs, {batch_output_placeholder: output_feed, inputs:feed_image})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESTORE MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta path: output/shallowunet/1/frozen/export.meta\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'data/test_data/'\n",
    "checkpoint = frozen_dir\n",
    "output_dir = os.path.join(checkpoint, 'images')\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "from time import time\n",
    "meta_path = os.path.join(checkpoint, 'export.meta')\n",
    "print('meta path:', meta_path)\n",
    "\n",
    "assert os.path.exists(meta_path), meta_path+' does not exist'\n",
    "tf.train.import_meta_graph(meta_path)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dir: data/test_data/\n"
     ]
    }
   ],
   "source": [
    "print('input_dir:', input_dir)\n",
    "paths = glob('{}/*.JPG'.format(input_dir))+glob('data/scaned/*.JPG')\n",
    "# paths = [path for path in paths if get_name(path).isdigit()]\n",
    "paths = ['xxx.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output/shallowunet/1/frozen/export\n",
      "num of params: 1043529\n",
      "Num of sample: 1 data/test_data/\n",
      "---------------------------\n",
      "process: xxx.jpg\n",
      "image: xxx.jpg \t shape:  (1351, 1014, 3)\n",
      " 0.67 %Output:  output/shallowunet/1/frozen/temp1/xxx\n",
      "Running time: 2.120087146759033\n",
      "Running time: 2.1201066970825195\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\n",
    "        checkpoint))\n",
    "\n",
    "    parameter_count = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in tf.trainable_variables()])\n",
    "    print('num of params:', sess.run(parameter_count))\n",
    "\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    start = time()\n",
    "\n",
    "    assert len(paths) > 0\n",
    "    print('Num of sample:', len(paths), input_dir)\n",
    "    inputs = get_tensor_by_name('inputs')\n",
    "    outputs = get_tensor_by_name('outputs')\n",
    "    batch_input_tensor = get_tensor_by_name('batch_input_tensor')\n",
    "    batch_input_placeholder = get_tensor_by_name('batch_input_placeholder')\n",
    "    batch_output_tensor = get_tensor_by_name('batch_output_tensor')\n",
    "    batch_output_placeholder = get_tensor_by_name('batch_output_placeholder')\n",
    "    start = time()\n",
    "    begin = start\n",
    "    for path in paths:\n",
    "        name = path.split('/')[-1].split('.')[0]\n",
    "        image = load_image(path, verbal=True)\n",
    "        print('image:', path, '\\t shape: ', image.shape)\n",
    "        output_image = run(sess, image)\n",
    "        save_dir = os.path.join(checkpoint, 'temp1/{}'.format(name))\n",
    "        save_output(image, output_image, save_dir)\n",
    "        print('Running time:', time()-start)\n",
    "\n",
    "\n",
    "    print('Running time:', time()-begin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
